from datetime import datetime
import enum
from urllib.parse import urlsplit

from elasticsearch_dsl import InnerDoc
from elasticsearch_metrics import metrics
from elasticsearch_metrics.signals import pre_save
from django.dispatch import receiver
import pytz

from osf.metrics.utils import stable_key


class PageviewInfo(InnerDoc):
    """PageviewInfo

    for CountedUsageV2 generated by viewing a web page
    """
    # fields that should be provided
    referer_url = metrics.Keyword()
    page_url = metrics.Keyword()
    page_title = metrics.Keyword()
    route_name = metrics.Keyword()  # TODO: analyze for filtering by prefix (split on '.')

    # fields autofilled from the above (see `autofill_fields`)
    page_path = metrics.Keyword()
    referer_domain = metrics.Keyword()
    hour_of_day = metrics.Integer()


class CountedUsageV2(metrics.Metric):
    """CountedUsageV2

    Something was used! Let's quickly take note of that and
    move on, then come back later to query/analyze/investigate.

    Aim to support a COUNTER-style reporting api
    (see https://cop5.projectcounter.org/en/5.0.2/)
    """

    # where noted, fields correspond to defined terms from COUNTER
    # https://cop5.projectcounter.org/en/5.0.2/appendices/a-glossary-of-terms.html
    platform_iri = metrics.Keyword()    # counter:Platform
    provider_id = metrics.Keyword()     # counter:Database
    item_guid = metrics.Keyword()       # counter:Item
    session_id = metrics.Keyword()      # counter:Session

    item_public = metrics.Boolean()

    action_labels = metrics.Keyword(multi=True)
    class ActionLabel(enum.Enum):
        SEARCH = 'search'       # counter:Search
        VIEW = 'view'           # counter:Investigation
        DOWNLOAD = 'download'   # counter:Request
        WEB = 'web'             # counter:Regular (aka "pageview")
        API = 'api'             # counter:TDM (aka "non-webclient api usage")
        # TODO: count api usage, distinguish between web and non-web api requests

    # pageviews get additional info to support the "node analytics" view
    # (see `api.metrics.views.NodeAnalyticsQuery`)
    pageview_info = metrics.Object(PageviewInfo)

    class Meta:
        dynamic = metrics.MetaField('strict')
        source = metrics.MetaField(enabled=True)


@receiver(pre_save, sender=CountedUsageV2)
def autofill_fields(sender, instance, **kwargs):
    pageview = getattr(instance, 'pageview_info', None)
    if pageview:
        pageview.hour_of_day = instance.timestamp.hour
        pageview.page_path = urlsplit(pageview.page_url).path.rstrip('/')
        referer = getattr(pageview, 'referer_url', None)
        if referer:
            pageview.referer_domain = urlsplit(referer).netloc

    # divide the day into 30-second windows, filter out
    # "double clicks" by removing duplicates within a window
    # (latest event wins, per COUNTER)
    day_start = datetime(
        instance.timestamp.year,
        instance.timestamp.month,
        instance.timestamp.day,
        tzinfo=pytz.utc,
    )
    time_in_seconds = (instance.timestamp - day_start).total_seconds()
    time_window = int(time_in_seconds / 30)

    if pageview is not None:
        target_identifier = pageview.page_url
    else:
        target_identifier = instance.item_guid

    # Set the document id to a hash of "unique together"
    # values to get "ON CONFLICT UPDATE" behavior -- if
    # the document already exists, it will be updated rather
    # than duplicated.  Cannot detect/avoid conflicts this way,
    # but that's ok.
    instance.meta.id = stable_key(
        instance.platform_iri,
        instance.provider_id,
        target_identifier,
        instance.session_id,
        instance.timestamp.date(),
        time_window,
    )
